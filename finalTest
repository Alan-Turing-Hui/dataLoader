import torch
import time
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, balanced_accuracy_score, accuracy_score

def test(model, test_loader, device, metrics_history):
    model.eval()  # 设置模型为评估模式

    y_true = []  # 存储真实标签
    y_pred = []  # 存储预测标签

    # 开始记录测试时间
    start_time = time.time()

    with torch.no_grad():  # 不需要计算梯度
        for data, targets in test_loader:
            data, targets = data.to(device), targets.to(device).float()

            # 初始化隐藏状态
            hidden = model.init_hidden(data.size(0))

            # 前向传播
            outputs, hidden = model(data, hidden)

            # 将输出转换为 0 或 1
            predicted = (outputs >= 0.5).float()  # 阈值 0.5

            # 将结果保存到列表中，转为CPU的numpy格式
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

    # 计算测试时间
    test_time = time.time() - start_time

    # 计算各种指标
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    roc_auc = roc_auc_score(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)
    balanced_acc = balanced_accuracy_score(y_true, y_pred)

    # 将指标保存到 metrics_history 中
    metrics_history['accuracy'].append(accuracy)
    metrics_history['precision'].append(precision)
    metrics_history['recall'].append(recall)
    metrics_history['f1'].append(f1)
    metrics_history['roc_auc'].append(roc_auc)
    metrics_history['balanced_accuracy'].append(balanced_acc)

    # 输出结果
    print(f'Accuracy: {accuracy:.4f}')
    print(f'Precision: {precision:.4f}')
    print(f'Recall: {recall:.4f}')
    print(f'F1 Score: {f1:.4f}')
    print(f'ROC AUC: {roc_auc:.4f}')
    print(f'Confusion Matrix:\n{conf_matrix}')
    print(f'Balanced Accuracy: {balanced_acc:.4f}')
    print(f'Test Time: {test_time:.2f} seconds')

    return test_time  # 返回测试时间
