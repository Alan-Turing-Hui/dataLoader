# 自定义数据集
class AudioDataset(Dataset):  
    def __init__(self, audio_files, labels):  
        self.audio_files = audio_files  
        self.labels = labels  # 使用目标标签  

    def __len__(self):  
        return len(self.audio_files)  

    def __getitem__(self, idx):  
        # 加载音频文件  
        waveform, sample_rate = torchaudio.load(self.audio_files[idx])  

        # pad_or_trim_waveform 函数假定已定义，需保证波形的长度  
        waveform = pad_or_trim_waveform(waveform, sample_rate * 12)  # 例如处理到12秒  
        # 提取梅尔频谱图  
        mel_specgram = torchaudio.transforms.MelSpectrogram(sample_rate)(waveform)  

        # 梅尔频谱图的标准化  
        mel_specgram_norm = (mel_specgram - mel_specgram.mean()) / mel_specgram.std()  
        
        # 调整为模型输入所需的格式  
        # 从 (channels, n_mels, time) 到 (batch_size, channels, height, width)  
        # 这里假设 mel_specgram_norm 是 (1, n_mels, time)，并添加 batch_size 维度  
        feature = mel_specgram_norm.unsqueeze(0)  # (1, 1, n_mels, time)  

        # 返回特征和标签  
        return feature, self.labels[idx]  

# 创建数据集,文件类型重新变回到列表
audioDataset = AudioDataset(audio_files.tolist(), labels.tolist())

# 创建数据加载器
dataLoader = DataLoader(audioDataset, batch_size=32, shuffle=True)

from torch.utils.data import random_split
# 设置训练集和测试集的比例
train_ratio = 0.8  # 80% 用于训练

# 计算数据集的大小
dataset_size = len(audioDataset)
train_size = int(train_ratio * dataset_size)
test_size = dataset_size - train_size  # 确保总数不变

# 划分数据集
train_dataset, test_dataset = random_split(audioDataset, [train_size, test_size])

# 创建数据加载器
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

#建构CNN网络
import torch.nn as nn
import torch.nn.functional as F

# 定义CNN模型
class AudioCNN(nn.Module):
    def __init__(self):
        super(AudioCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3))
        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3))
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 62 * 62, 128)  # 根据输入调整
        self.fc2 = nn.Linear(128, 1)  # 二分类，若多类可用softmax

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 62 * 62)  # 根据输入调整
        x = F.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))  # 二分类
        return x
