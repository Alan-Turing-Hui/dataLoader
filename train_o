def train(model, train_loader, epoch, num_epochs, optimizer):
    model.train()  # 设置模型为训练模式
    running_loss = 0.0

    for batch_idx, (data, targets) in enumerate(train_loader):
        # 将数据和目标转移到设备
        data, targets = data.to(device), targets.to(device).float()  # 确保目标是浮点数

        # 初始化隐藏状态
        hidden = model.init_hidden(data.size(0))

        # 清零梯度
        optimizer.zero_grad()

        # 前向传播
        outputs, hidden = model(data, hidden)

        # 计算损失
        loss = criterion(outputs, targets.unsqueeze(1))  # 添加一个维度以匹配输出形状

        # 反向传播和优化
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # 输出每个 epoch 的损失
        if batch_idx % 10 == 0:  # 每 10 个 batch 打印一次
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')

    average_loss = running_loss / len(train_loader)
    train_losses.append(average_loss)  # 保存训练损失
    print(f'Average Loss for Epoch [{epoch+1}]: {average_loss:.4f}')
